{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5003 project code\n",
    "\n",
    "#### In this projec, we implemented pair programming through vscode live share. Thus, we tried the findspark to start our spark in vscode below. We shoud install findspark first.\n",
    "\n",
    "%pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in /Users/zhanghousu/conda/lib/python3.9/site-packages (2.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:07:08 WARN Utils: Your hostname, MacBook-Pro-279.local resolves to a loopback address: 127.0.0.1; using 10.79.140.225 instead (on interface en0)\n",
      "23/04/23 16:07:08 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:07:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/23 16:07:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/04/23 16:07:10 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "23/04/23 16:07:10 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "\n",
    "findspark.init(spark_home='/Users/zhanghousu/spark/spark-3.3.1-bin-hadoop2',\n",
    "                python_path='/Users/zhanghousu/conda/bin/python')\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the files in RDD\n",
    "credits = sc.textFile('data/credits.csv')\n",
    "links = sc.textFile('data/links.csv')\n",
    "ratings = sc.textFile('data/ratings.csv')\n",
    "movies_metadata = sc.textFile('data/movies_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:07:21 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 0 (TID 0): Attempting to kill Python Worker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:07:28 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 4 (TID 10): Attempting to kill Python Worker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:07:41 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 6 (TID 33): Attempting to kill Python Worker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession(sc)\n",
    "cred_df = spark.read.csv(credits, header=True, inferSchema=True, escape='\"')\n",
    "links_df = spark.read.csv(links, header=True, inferSchema=True, escape='\"')\n",
    "ratings_df = spark.read.csv(ratings, header=True, inferSchema=True, escape='\"')\n",
    "movies_metadata_df = spark.read.csv(movies_metadata, header=True, inferSchema=True, escape='\"')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleanning credit dataset\n",
    "#### calculating null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+\n",
      "|cast|crew| id|\n",
      "+----+----+---+\n",
      "|   0|   0|  0|\n",
      "+----+----+---+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# calucate the null values in each column\n",
    "null_rows = cred_df.select(*[(sum(when(isnull(c), 1).otherwise(0))).alias(c) for c in cred_df.columns])\n",
    "null_rows.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+---+\n",
      "|cast|crew| id|\n",
      "+----+----+---+\n",
      "|   0|   0|  0|\n",
      "+----+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop the rows with null values\n",
    "cred_df_n = cred_df.dropna()\n",
    "null_rows_check = cred_df_n.select(*[(sum(when(isnull(c), 1).otherwise(0))).alias(c) for c in cred_df_n.columns])\n",
    "null_rows_check.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cleanning metadata dataset\n",
    "#### removing useless features, calculating null data, data StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45572"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop useless columns\n",
    "mv_meta_df_dp = movies_metadata_df.drop('adult', 'belongs_to_collection', 'homepage', 'imdb_id', \n",
    "                                        'original_title', 'overview', 'poster_path', 'release_date', \n",
    "                                        'spoken_languages', 'title', 'tagline', 'video')\n",
    "\n",
    "# show the size of the mv_meta_df_dp\n",
    "mv_meta_df_dp.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44941"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete the rows with status not equal to \"Released\"\n",
    "mv_meta_df_dp = mv_meta_df_dp.filter(col(\"status\") == \"Released\")\n",
    "mv_meta_df_dp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 20:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:07:51 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 20 (TID 56): Attempting to kill Python Worker\n",
      "+--------+--------------------+-----+-----------------+----------+--------------------+--------------------+---------+-------+------------+----------+\n",
      "|  budget|              genres|   id|original_language|popularity|production_companies|production_countries|  revenue|runtime|vote_average|vote_count|\n",
      "+--------+--------------------+-----+-----------------+----------+--------------------+--------------------+---------+-------+------------+----------+\n",
      "|30000000|[{'id': 16, 'name...|  862|               en| 21.946943|[{'name': 'Pixar ...|[{'iso_3166_1': '...|373554033|   81.0|         7.7|      5415|\n",
      "|65000000|[{'id': 12, 'name...| 8844|               en| 17.015539|[{'name': 'TriSta...|[{'iso_3166_1': '...|262797249|  104.0|         6.9|      2413|\n",
      "|       0|[{'id': 10749, 'n...|15602|               en|   11.7129|[{'name': 'Warner...|[{'iso_3166_1': '...|        0|  101.0|         6.5|        92|\n",
      "|16000000|[{'id': 35, 'name...|31357|               en|  3.859495|[{'name': 'Twenti...|[{'iso_3166_1': '...| 81452156|  127.0|         6.1|        34|\n",
      "|       0|[{'id': 35, 'name...|11862|               en|  8.387519|[{'name': 'Sandol...|[{'iso_3166_1': '...| 76578911|  106.0|         5.7|       173|\n",
      "+--------+--------------------+-----+-----------------+----------+--------------------+--------------------+---------+-------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# remove status column\n",
    "mv_meta_df_dp = mv_meta_df_dp.drop('status')\n",
    "mv_meta_df_dp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34065"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the rows with budget and revenue equal to 0\n",
    "mv_meta_df_dp = mv_meta_df_dp.filter((col(\"budget\") == 0) & (col(\"revenue\") == 0))\n",
    "mv_meta_df_dp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:07:56 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 24 (TID 60): Attempting to kill Python Worker\n",
      "+--------------------+-----+-----------------+----------+--------------------+--------------------+-------+------------+----------+\n",
      "|              genres|   id|original_language|popularity|production_companies|production_countries|runtime|vote_average|vote_count|\n",
      "+--------------------+-----+-----------------+----------+--------------------+--------------------+-------+------------+----------+\n",
      "|[{'id': 10749, 'n...|15602|               en|   11.7129|[{'name': 'Warner...|[{'iso_3166_1': '...|  101.0|         6.5|        92|\n",
      "|[{'id': 28, 'name...|45325|               en|  2.561161|[{'name': 'Walt D...|[{'iso_3166_1': '...|   97.0|         5.4|        45|\n",
      "|[{'id': 35, 'name...|12110|               en|  5.430331|[{'name': 'Columb...|[{'iso_3166_1': '...|   88.0|         5.7|       210|\n",
      "|[{'id': 18, 'name...| 1710|               en| 10.701801|[{'name': 'Regenc...|[{'iso_3166_1': '...|  124.0|         6.5|       199|\n",
      "|[{'id': 18, 'name...|12665|               en| 12.133094|[{'name': 'Carava...|[{'iso_3166_1': '...|  111.0|         6.3|       143|\n",
      "+--------------------+-----+-----------------+----------+--------------------+--------------------+-------+------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "mv_meta_df_dp = mv_meta_df_dp.drop('budget', 'revenue')\n",
    "mv_meta_df_dp.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genres: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- popularity: string (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- vote_average: string (nullable = true)\n",
      " |-- vote_count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mv_meta_df_dp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- genres: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- original_language: string (nullable = true)\n",
      " |-- popularity: double (nullable = true)\n",
      " |-- production_companies: string (nullable = true)\n",
      " |-- production_countries: string (nullable = true)\n",
      " |-- runtime: double (nullable = true)\n",
      " |-- vote_average: double (nullable = true)\n",
      " |-- vote_count: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# create DoubleType list\n",
    "columns_to_convert = [\"popularity\", \"runtime\", \"vote_average\", \"vote_count\"]\n",
    "\n",
    "# convert the columns to DoubleType\n",
    "for column in columns_to_convert:\n",
    "    mv_meta_df_dp = mv_meta_df_dp.withColumn(column, mv_meta_df_dp[column].cast(DoubleType()))\n",
    "\n",
    "# check the schema\n",
    "mv_meta_df_dp.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:14:55 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 50 (TID 86): Attempting to kill Python Worker\n",
      "+--------------------+-----+-----------------+-------------------+--------------------+--------------------+--------------------+-------------------+------------------+\n",
      "|              genres|   id|original_language|         popularity|production_companies|production_countries|             runtime|       vote_average|        vote_count|\n",
      "+--------------------+-----+-----------------+-------------------+--------------------+--------------------+--------------------+-------------------+------------------+\n",
      "|[{'id': 10749, 'n...|15602|               en|  4.206316413101168|[{'name': 'Warner...|[{'iso_3166_1': '...| 0.24766515838470915| 0.4855626862661089|1.5891692288003527|\n",
      "|[{'id': 28, 'name...|45325|               en|0.37941274243353634|[{'name': 'Walt D...|[{'iso_3166_1': '...|  0.1497112793968787|-0.0461136633509578|0.5691413503944264|\n",
      "|[{'id': 35, 'name...|12110|               en| 1.5791887855188393|[{'name': 'Columb...|[{'iso_3166_1': '...|-0.07068494832573984|0.09888897745369672| 4.150090285223742|\n",
      "|[{'id': 18, 'name...| 1710|               en| 3.7835138752984205|[{'name': 'Regenc...|[{'iso_3166_1': '...|  0.8108999625647342| 0.4855626862661089|3.9113603562351202|\n",
      "|[{'id': 18, 'name...|12665|               en|  4.382025309628101|[{'name': 'Carava...|[{'iso_3166_1': '...| 0.49254985585428523|0.38889425906300573| 2.696007990474868|\n",
      "+--------------------+-----+-----------------+-------------------+--------------------+--------------------+--------------------+-------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, stddev, col\n",
    "\n",
    "# create a list of columns to normalize\n",
    "for column in columns_to_convert:\n",
    "    # calculate the mean and standard deviation\n",
    "    mean_value, stddev_value = mv_meta_df_dp.select(mean(col(column)), stddev(col(column))).first()\n",
    "\n",
    "    # normalize the column\n",
    "    mv_meta_df_dp = mv_meta_df_dp.withColumn(column, (col(column) - mean_value) / stddev_value)\n",
    "\n",
    "mv_meta_df_dp.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 51:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:15:00 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 51 (TID 87): Attempting to kill Python Worker\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|                cast|                crew|   id|            cast_new|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "|[{'cast_id': 14, ...|[{'credit_id': '5...|  862|[{'cast_id': 14, ...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...| 8844|[{'cast_id': 1, '...|\n",
      "|[{'cast_id': 2, '...|[{'credit_id': '5...|15602|[{'cast_id': 2, '...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|31357|[{'cast_id': 1, '...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|11862|[{'cast_id': 1, '...|\n",
      "|[{'cast_id': 25, ...|[{'credit_id': '5...|  949|[{'cast_id': 25, ...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|11860|[{'cast_id': 1, '...|\n",
      "|[{'cast_id': 2, '...|[{'credit_id': '5...|45325|[{'cast_id': 2, '...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...| 9091|[{'cast_id': 1, '...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|  710|[{'cast_id': 1, '...|\n",
      "+--------------------+--------------------+-----+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "def helper(input_str):\n",
    "    return input_str.replace(\"None\", \"'None'\")\n",
    "\n",
    "helper_udf = udf(helper)\n",
    "\n",
    "new_df = cred_df.withColumn(\"cast_new\", helper_udf(\"cast\"))\n",
    "new_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:26:08 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 57 (TID 93): Attempting to kill Python Worker\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|                cast|                crew|   id|            cast_new|          cast_array|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "|[{'cast_id': 14, ...|[{'credit_id': '5...|  862|[{'cast_id': 14, ...|[{Tom Hanks}, {Ti...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...| 8844|[{'cast_id': 1, '...|[{Robin Williams}...|\n",
      "|[{'cast_id': 2, '...|[{'credit_id': '5...|15602|[{'cast_id': 2, '...|[{Walter Matthau}...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|31357|[{'cast_id': 1, '...|[{Whitney Houston...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|11862|[{'cast_id': 1, '...|[{Steve Martin}, ...|\n",
      "|[{'cast_id': 25, ...|[{'credit_id': '5...|  949|[{'cast_id': 25, ...|[{Al Pacino}, {Ro...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|11860|[{'cast_id': 1, '...|[{Harrison Ford},...|\n",
      "|[{'cast_id': 2, '...|[{'credit_id': '5...|45325|[{'cast_id': 2, '...|[{Jonathan Taylor...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...| 9091|[{'cast_id': 1, '...|[{Jean-Claude Van...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|  710|[{'cast_id': 1, '...|[{Pierce Brosnan}...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...| 9087|[{'cast_id': 1, '...|[{Michael Douglas...|\n",
      "|[{'cast_id': 9, '...|[{'credit_id': '5...|12110|[{'cast_id': 9, '...|[{Leslie Nielsen}...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|21032|[{'cast_id': 1, '...|[{Kevin Bacon}, {...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|10858|[{'cast_id': 1, '...|[{Anthony Hopkins...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...| 1408|[{'cast_id': 1, '...|[{Geena Davis}, {...|\n",
      "|[{'cast_id': 4, '...|[{'credit_id': '5...|  524|[{'cast_id': 4, '...|[{Robert De Niro}...|\n",
      "|[{'cast_id': 6, '...|[{'credit_id': '5...| 4584|[{'cast_id': 6, '...|[{Kate Winslet}, ...|\n",
      "|[{'cast_id': 42, ...|[{'credit_id': '5...|    5|[{'cast_id': 42, ...|[{Tim Roth}, {Ant...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...| 9273|[{'cast_id': 1, '...|[{Jim Carrey}, {I...|\n",
      "|[{'cast_id': 1, '...|[{'credit_id': '5...|11517|[{'cast_id': 1, '...|[{Wesley Snipes},...|\n",
      "+--------------------+--------------------+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json, col, explode, get_json_object, array\n",
    "from pyspark.sql.types import StructType, StructField,\\\n",
    "    StringType, IntegerType, ArrayType\n",
    "\n",
    "json_schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "])\n",
    "\n",
    "# Parse the JSON array and add it as a new column 'cast_array'\n",
    "new_df1 = new_df.withColumn(\"cast_array\", from_json(col(\"cast_new\"), ArrayType(json_schema)))\n",
    "\n",
    "new_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 58:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/23 16:26:42 WARN PythonRunner: Detected deadlock while completing task 0.0 in stage 58 (TID 94): Attempting to kill Python Worker\n",
      "+-----------------+----+\n",
      "|             cast|  id|\n",
      "+-----------------+----+\n",
      "|        Tom Hanks| 862|\n",
      "|        Tim Allen| 862|\n",
      "|      Don Rickles| 862|\n",
      "|       Jim Varney| 862|\n",
      "|    Wallace Shawn| 862|\n",
      "|John Ratzenberger| 862|\n",
      "|      Annie Potts| 862|\n",
      "|      John Morris| 862|\n",
      "|  Erik von Detten| 862|\n",
      "|   Laurie Metcalf| 862|\n",
      "|     R. Lee Ermey| 862|\n",
      "|    Sarah Freeman| 862|\n",
      "|    Penn Jillette| 862|\n",
      "|   Robin Williams|8844|\n",
      "|    Jonathan Hyde|8844|\n",
      "|    Kirsten Dunst|8844|\n",
      "|   Bradley Pierce|8844|\n",
      "|      Bonnie Hunt|8844|\n",
      "|    Bebe Neuwirth|8844|\n",
      "| David Alan Grier|8844|\n",
      "+-----------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "casts = new_df1.select(explode(col(\"cast_array\")[\"name\"]).alias(\"cast\"),\"id\")\n",
    "casts.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct categories count: 3198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "distinct_categories_count = mv_meta_df_dp.select(\"genres\").distinct().count()\n",
    "\n",
    "# 输出结果\n",
    "print(\"Distinct categories count:\", distinct_categories_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
